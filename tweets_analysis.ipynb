{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b50e60a",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Tweets about Apple and Google Products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6439856a",
   "metadata": {},
   "source": [
    "### Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4d9734",
   "metadata": {},
   "source": [
    "\n",
    "This notebook builds an NLP model to classify sentiment in tweets directed at Apple and Google products.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81606938",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b709f89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download(\"punkt\")\n",
    "#nltk.download(\"punkt_tab\")\n",
    "#nltk.download(\"wordnet\")\n",
    "#nltk.download(\"omw-1.4\")\n",
    "#nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df11e1",
   "metadata": {},
   "source": [
    "### Step 1: Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49212dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tweet_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "emotion_in_tweet_is_directed_at",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_there_an_emotion_directed_at_a_brand_or_product",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "cb5a0307-c7be-4a43-8693-f1390a79290e",
       "rows": [
        [
         "0",
         ".@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.",
         "iPhone",
         "Negative emotion"
        ],
        [
         "1",
         "@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW",
         "iPad or iPhone App",
         "Positive emotion"
        ],
        [
         "2",
         "@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.",
         "iPad",
         "Positive emotion"
        ],
        [
         "3",
         "@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw",
         "iPad or iPhone App",
         "Negative emotion"
        ],
        [
         "4",
         "@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)",
         "Google",
         "Positive emotion"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the CSV file with correct encoding (ISO-8859-1 works for many text datasets)\n",
    "df = pd.read_csv('Data\\judge-1377884607_tweet_product_company.csv', encoding='Latin-1')\n",
    "\n",
    "# Displaying the first 5 rows of the dataset\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79733fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4aca66",
   "metadata": {},
   "source": [
    "### Step 2: Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e93d396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing text\n",
    "df.dropna(subset=[\"tweet_text\"], inplace=True)\n",
    "df.fillna({'emotion_in_tweet_is_directed_at': 'Unknown'}, inplace=True)\n",
    "\n",
    "# Reset index\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14d364c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "5eb0d988-8964-4321-9de7-2f4c15760f25",
       "rows": [
        [
         "tweet_text",
         "0"
        ],
        [
         "emotion_in_tweet_is_directed_at",
         "0"
        ],
        [
         "is_there_an_emotion_directed_at_a_brand_or_product",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 3
       }
      },
      "text/plain": [
       "tweet_text                                            0\n",
       "emotion_in_tweet_is_directed_at                       0\n",
       "is_there_an_emotion_directed_at_a_brand_or_product    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef7d354",
   "metadata": {},
   "source": [
    "### Step 3: Basic Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44dc9693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "    # Remove user mentions\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r\"[^A-Za-z\\s]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "df[\"clean_text\"] = df[\"tweet_text\"].apply(clean_tweet_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475ff655",
   "metadata": {},
   "source": [
    "### Step 4: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6b081b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokens\"] = df[\"clean_text\"].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d062af6",
   "metadata": {},
   "source": [
    "### Step 5: Stopward Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2fcf6072",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "df[\"tokens\"] = df[\"tokens\"].apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d81351",
   "metadata": {},
   "source": [
    "### Step 6: Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2e78897",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "df[\"tokens\"] = df[\"tokens\"].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe29712",
   "metadata": {},
   "source": [
    "### Step 7: Join Tokens Back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b74adade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"processed_text\"] = df[\"tokens\"].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392f2def",
   "metadata": {},
   "source": [
    "### Step 8: Vectorization (TF-IDF Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9670b2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF - IDF shape (9092, 5000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df[\"processed_text\"])\n",
    "\n",
    "print('TF - IDF shape', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a6e3a1",
   "metadata": {},
   "source": [
    "### Step 9: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c7b34a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (7273, 5000)\n",
      "Test size: (1819, 5000)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, df[\"is_there_an_emotion_directed_at_a_brand_or_product\"], test_size=0.2, random_state=42)\n",
    "print(\"Train size:\", X_train.shape)\n",
    "print(\"Test size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f611b",
   "metadata": {},
   "source": [
    "## Refactoring the steps above into a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "06970c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           tweet_text  \\\n",
      "0   I G iPhone After hr tweeting dead I need upgra...   \n",
      "1   Know Awesome iPadiPhone app youll likely appre...   \n",
      "2                             Can wait also They sale   \n",
      "3    I hope year festival isnt crashy year iPhone app   \n",
      "4   great stuff Fri Marissa Mayer Google Tim OReil...   \n",
      "5   New iPad Apps For And Communication Are Showca...   \n",
      "7   starting around corner hop skip jump good time...   \n",
      "8     Beautifully smart simple idea RT wrote iPad app   \n",
      "9   Counting day plus strong Canadian dollar mean ...   \n",
      "10  Excited meet I show Sprint Galaxy S still runn...   \n",
      "\n",
      "   emotion_in_tweet_is_directed_at  \\\n",
      "0                           iPhone   \n",
      "1               iPad or iPhone App   \n",
      "2                             iPad   \n",
      "3               iPad or iPhone App   \n",
      "4                           Google   \n",
      "5                          Unknown   \n",
      "7                          Android   \n",
      "8               iPad or iPhone App   \n",
      "9                            Apple   \n",
      "10                         Android   \n",
      "\n",
      "   is_there_an_emotion_directed_at_a_brand_or_product  \n",
      "0                                    Negative emotion  \n",
      "1                                    Positive emotion  \n",
      "2                                    Positive emotion  \n",
      "3                                    Negative emotion  \n",
      "4                                    Positive emotion  \n",
      "5                  No emotion toward brand or product  \n",
      "7                                    Positive emotion  \n",
      "8                                    Positive emotion  \n",
      "9                                    Positive emotion  \n",
      "10                                   Positive emotion  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Download NLTK resources (leave commented if already downloaded)\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"wordnet\")\n",
    "# nltk.download(\"omw-1.4\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# -------------------------------\n",
    "# Custom Preprocessor\n",
    "# -------------------------------\n",
    "\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, text_column):\n",
    "        self.text_column = text_column\n",
    "\n",
    "    def clean_text(self,text):\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text) # remove urls\n",
    "        text = re.sub(r\"@\\w+\", \"\", text) # remove mentions\n",
    "        text = re.sub(r\"#\\w+\", \"\", text) # remove hashtags\n",
    "        text = re.sub(r\"[^A-Za-z\\s]\", \"\", text) # remove special characters\n",
    "        return text.strip()\n",
    "    \n",
    "    def tokenize_lemmatize(self, text):\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [t for t in tokens if t not in stop_words]\n",
    "        tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "        return \" \".join(tokens)\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_filled = X.copy()\n",
    "        \n",
    "        # Fill missing values in the second column\n",
    "        second_col = X_filled.columns[1]\n",
    "        X_filled[second_col] = X_filled[second_col].fillna(\"Unknown\")\n",
    "        \n",
    "        # Process the text column\n",
    "        X_filled[self.text_column] = X_filled[self.text_column].apply(\n",
    "            lambda t: self.tokenize_lemmatize(self.clean_text(t))\n",
    "        )\n",
    "        \n",
    "        return X_filled  # return as DataFrame\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "# -------------------------------\n",
    "# Load Dataset\n",
    "# -------------------------------\n",
    "    \n",
    "df = pd.read_csv(\"Data\\judge-1377884607_tweet_product_company.csv\", encoding='Latin-1')\n",
    "\n",
    "df.dropna(subset=[\"tweet_text\"], inplace=True)\n",
    "\n",
    "X = df[\"tweet_text\"]\n",
    "\n",
    "# -------------------------------\n",
    "# Build Preprocessing Pipeline\n",
    "# -------------------------------\n",
    "\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    (\"text_preprocessor\", TextPreprocessor(text_column=\"tweet_text\"))\n",
    "])\n",
    "\n",
    "# Apply Pipeline\n",
    "df_preprocessed = preprocessing_pipeline.fit_transform(df)\n",
    "\n",
    "# view processed tweets\n",
    "print(df_preprocessed.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
